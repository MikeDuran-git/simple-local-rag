{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for GPU access\n",
    "print(\"GPU available: \", torch.cuda.is_available())\n",
    "print(\"Current device: \", torch.cuda.current_device())\n",
    "print(\"Device name: \", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 1: Load and Preprocess the Dataset\n",
    "def load_and_preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['text'] = df.apply(lambda row: f\"{row['title']} {row['ingredients']} {row['directions']}\", axis=1)\n",
    "    return df['text'].tolist()\n",
    "\n",
    "# Load and preprocess data\n",
    "data_file = 'RecipeNLG_dataset_small.csv'\n",
    "texts = load_and_preprocess_data(data_file)\n",
    "\n",
    "# Save preprocessed texts to a file for TextDataset usage\n",
    "with open(\"recipes.txt\", \"w\") as f:\n",
    "    for text in texts:\n",
    "        f.write(text + \"\\n\")\n",
    "\n",
    "# Step 2: Set Up the GPT-2 Model for Fine-Tuning\n",
    "model_name = \"gpt2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike Duran\\OneDrive - Actimage GmbH\\Desktop\\simple-local-rag\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TextDataset\n",
    "def load_dataset(file_path, tokenizer, block_size=128):\n",
    "    return TextDataset(\n",
    "        tokenizer=tokenizer,\n",
    "        file_path=file_path,\n",
    "        block_size=block_size\n",
    "    )\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike Duran\\OneDrive - Actimage GmbH\\Desktop\\simple-local-rag\\.venv\\Lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"recipes.txt\", tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (0.33.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.17 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from accelerate) (6.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from accelerate) (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (1.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mike duran\\onedrive - actimage gmbh\\desktop\\simple-local-rag\\.venv\\lib\\site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/accelerate/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/accelerate/\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the Fine-Tuned Model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2-recipe-finetuned\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mike Duran\\OneDrive - Actimage GmbH\\Desktop\\simple-local-rag\\.venv\\Lib\\site-packages\\accelerate\\accelerator.py:451: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7d8f01eb154d8da967819113801bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1602 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Save the Fine-Tuned Model\n",
    "model.save_pretrained(\"./gpt2-recipe-finetuned\")\n",
    "tokenizer.save_pretrained(\"./gpt2-recipe-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Create the generate_response Method\n",
    "def generate_response(prompt, context, model, tokenizer, max_length=100):\n",
    "    input_text = f\"{context} {prompt}\"\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "    \n",
    "    output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=max_length,\n",
    "        num_return_sequences=1,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Example usage of generate_response\n",
    "finetuned_model = GPT2LMHeadModel.from_pretrained(\"./gpt2-recipe-finetuned\")\n",
    "finetuned_tokenizer = GPT2Tokenizer.from_pretrained(\"./gpt2-recipe-finetuned\")\n",
    "\n",
    "prompt = \"How do I make a chocolate cake?\"\n",
    "context = \"Here is a recipe for a delicious chocolate cake.\"\n",
    "\n",
    "response = generate_response(prompt, context, finetuned_model, finetuned_tokenizer)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
